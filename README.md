## 关于

* 最近的兴趣方向不在这一块,可能更新的实例比较少。
* 有些程序估计写的比较早,一些网站的验证机制估计也变了,只做参考用。
* 虽然自己写的估计比较少，但是这里我会收集一些爬虫技巧链接。

## 爬虫实例

* Readme_Luowang:关于如何爬取落网音乐，下载到本地的小程序。
* Readme_Baidu:关于如何基于 Py2.7 根据关键词从百度下载图片的小程序
* Readme_Zhihu:关于如何抓取知乎上一些信息的程序。


**详细步骤可以阅读对应的 ReadMe 文件，相应代码都在本仓库中**


## 爬虫基础

* [Scrapy 爬爬取豆瓣信息并用 MongoDB 存储](http://1992mrwang.blog.51cto.com/3265935/1583539)
* [Scrapy 爬取知乎用户数据并用 MySQL 存储](http://python.jobbole.com/85125/)
* [Python 爬虫技巧总结,Cookies处理,get(),post(),以及如何伪装成浏览器等](http://www.codeceo.com/article/python-spider-skills.html#0-tsina-1-54529-397232819ff9a47a7b7e80a40613cfe1)
* [Python 爬虫学习系列教程,非常好，入门系列](http://cuiqingcai.com/1052.html)
* [Python 工程师,很全面的 Python 技术,在知乎有专栏](http://zhuanlan.zhihu.com/xlz-d)

## 爬虫进阶 

* [**Requests 库**](http://cn.python-requests.org/zh_CN/latest/user/quickstart.html)
* [**BeautifulSoup 库**](http://beautifulsoup.readthedocs.io/zh_CN/latest/)
* [Scrapy入门文档](http://scrapy-chs.readthedocs.org/zh_CN/0.24/intro/tutorial.html)
* [Scrapy初级实战](http://www.ituring.com.cn/article/114408)
* [Scrapy初级实战之数据可视化](http://aljun.me/post/9)

## 参与人员

* [TZS](https://github.com/1041218129)
* [DLX4](https://github.com/DLX4)


